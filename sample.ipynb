{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "640d8481dbea18f0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:06:45.570940Z",
     "start_time": "2026-01-22T15:06:45.551092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import json"
   ],
   "id": "e5580ea59e31feb6",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:07:55.192754Z",
     "start_time": "2026-01-22T15:07:55.176601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MERCH_DIR = Path(\"merchados\")   # WSL path to C:\\Sparrows\\merchados\n",
    "OUT_JSONL = Path(\"Sparrows/tasks_merchados.jsonl\")"
   ],
   "id": "c57a466d00c31b7e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:07:59.017274Z",
     "start_time": "2026-01-22T15:07:59.003186Z"
    }
   },
   "cell_type": "code",
   "source": "LS_PREFIX = \"/data/local-files/?d=merchados/\"",
   "id": "dc841b388ceba0fb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:07:59.646249Z",
     "start_time": "2026-01-22T15:07:59.635221Z"
    }
   },
   "cell_type": "code",
   "source": "base_re = re.compile(r\"^(?P<bird>.+)_(?P<date>\\d{4}-\\d{2}-\\d{2})$\")",
   "id": "473e590c43bb40e8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:08:00.000580Z",
     "start_time": "2026-01-22T15:07:59.992252Z"
    }
   },
   "cell_type": "code",
   "source": "base_re = re.compile(r\"^(?P<bird>.+)_(?P<date>\\d{4}-\\d{2}-\\d{2})$\")",
   "id": "34e815770e505a8d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:08:00.591044Z",
     "start_time": "2026-01-22T15:08:00.392101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- INDEX FILES ----\n",
    "all_files = {p.name for p in MERCH_DIR.iterdir() if p.is_file()}\n",
    "\n"
   ],
   "id": "c836ef43dcbbc6dc",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:08:02.608683Z",
     "start_time": "2026-01-22T15:08:02.594353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Find all \"base\" from merged csvs (BIRD_DATE.csv), ignoring *_raw_sig.csv\n",
    "bases = []"
   ],
   "id": "96b882b7b874666",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:09:02.907060Z",
     "start_time": "2026-01-22T15:09:02.892498Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for fn in all_files:\n",
    "    if fn.endswith(\".csv\") and not fn.endswith(\"_raw_sig.csv\"):\n",
    "        stem = fn[:-4]  # remove .csv\n",
    "        if base_re.match(stem):\n",
    "            bases.append(stem)\n",
    "\n",
    "bases = sorted(set(bases))\n",
    "\n",
    "tasks = []\n",
    "missing = {\"wav\": 0, \"raw\": 0, \"merged\": 0}\n",
    "\n",
    "for base in bases:\n",
    "    m = base_re.match(base)\n",
    "    bird_id = m.group(\"bird\")\n",
    "    date = m.group(\"date\")\n",
    "\n",
    "    merged_fn = f\"{base}.csv\"\n",
    "    wav_fn    = f\"{base}.wav\"\n",
    "    raw_fn    = f\"{base}_raw_sig.csv\"\n",
    "\n",
    "    ok = True\n",
    "    if merged_fn not in all_files:\n",
    "        missing[\"merged\"] += 1\n",
    "        ok = False\n",
    "    if wav_fn not in all_files:\n",
    "        missing[\"wav\"] += 1\n",
    "        ok = False\n",
    "    if raw_fn not in all_files:\n",
    "        missing[\"raw\"] += 1\n",
    "        ok = False\n",
    "\n",
    "    if not ok:\n",
    "        continue\n",
    "\n",
    "    task = {\n",
    "        \"data\": {\n",
    "            \"audio\":  f\"{LS_PREFIX}{wav_fn}\",\n",
    "            \"merged\": f\"{LS_PREFIX}{merged_fn}\",\n",
    "            \"raw\":    f\"{LS_PREFIX}{raw_fn}\",\n",
    "            \"bird_id\": bird_id,\n",
    "            \"date\": date,\n",
    "            \"base_id\": base\n",
    "        }\n",
    "    }\n",
    "    tasks.append(task)"
   ],
   "id": "4635e1c3310a421b",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T15:09:09.268329Z",
     "start_time": "2026-01-22T15:09:09.249489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- WRITE JSONL ----\n",
    "OUT_JSONL.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for t in tasks:\n",
    "        f.write(json.dumps(t, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(\"MERCH_DIR:\", MERCH_DIR)\n",
    "print(\"Wrote JSONL:\", OUT_JSONL)\n",
    "print(\"Tasks written:\", len(tasks))\n",
    "print(\"Skipped because missing files:\", missing)\n",
    "\n",
    "#note"
   ],
   "id": "37a45c81ad2f06cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MERCH_DIR: merchados\n",
      "Wrote JSONL: Sparrows\\tasks_merchados.jsonl\n",
      "Tasks written: 2946\n",
      "Skipped because missing files: {'wav': 0, 'raw': 0, 'merged': 0}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T16:16:12.891161Z",
     "start_time": "2026-01-22T16:14:47.494458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "MERCH_DIR = Path(\"merchados\")  # adjust if needed\n",
    "\n",
    "raw_files = sorted(MERCH_DIR.glob(\"*_raw_sig.csv\"))\n",
    "print(\"Found raw files:\", len(raw_files))\n",
    "\n",
    "fixed = 0\n",
    "bad = 0\n",
    "\n",
    "for p in raw_files:\n",
    "    df = pd.read_csv(p)\n",
    "\n",
    "    if \"ts\" not in df.columns:\n",
    "        bad += 1\n",
    "        continue\n",
    "\n",
    "    # Parse to datetime (handles nanoseconds if present)\n",
    "    ts = pd.to_datetime(df[\"ts\"], errors=\"coerce\")\n",
    "\n",
    "    # If parsing failed for many rows, skip and report\n",
    "    if ts.isna().mean() > 0.5:\n",
    "        bad += 1\n",
    "        continue\n",
    "\n",
    "    # Format as \"YYYY-mm-dd HH:MM:SS.mmm\" (3-digit milliseconds)\n",
    "    ts_str = ts.dt.strftime(\"%Y-%m-%d %H:%M:%S.\") + ts.dt.strftime(\"%f\").str[:3]\n",
    "\n",
    "    df[\"ts\"] = ts_str\n",
    "\n",
    "    # IMPORTANT: sort by time for Label Studio TimeSeries\n",
    "    df = df.sort_values(\"ts\")\n",
    "\n",
    "    df.to_csv(p, index=False)\n",
    "    fixed += 1\n",
    "\n",
    "print(\"Fixed files:\", fixed)\n",
    "print(\"Skipped/Bad files:\", bad)"
   ],
   "id": "ab08c2b3b339831e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found raw files: 2946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorge\\AppData\\Local\\Temp\\ipykernel_29660\\360845781.py:20: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ts = pd.to_datetime(df[\"ts\"], errors=\"coerce\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed files: 2946\n",
      "Skipped/Bad files: 0\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-22T16:16:22.120131Z",
     "start_time": "2026-01-22T16:16:22.091171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "p = sorted(Path(\"merchados\").glob(\"*_raw_sig.csv\"))[0]\n",
    "df = pd.read_csv(p)\n",
    "print(df[\"ts\"].head().tolist())"
   ],
   "id": "761536c5aa7981c9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020-01-17 08:40:57.293', '2020-01-17 08:41:16.591', '2020-01-17 08:41:35.888', '2020-01-17 08:41:55.186', '2020-01-17 08:42:14.484']\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "6c1a7a43b16dff81"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
